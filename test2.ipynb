{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'responses': [{'textAnnotations': [{'locale': 'und', 'description': 'dog\\nCat', 'boundingPoly': {'vertices': [{'x': 542, 'y': 51}, {'x': 671, 'y': 51}, {'x': 671, 'y': 185}, {'x': 542, 'y': 185}]}}, {'description': 'dog', 'boundingPoly': {'vertices': [{'x': 543, 'y': 55}, {'x': 667, 'y': 53}, {'x': 668, 'y': 140}, {'x': 544, 'y': 142}]}}, {'description': 'Cat', 'boundingPoly': {'vertices': [{'x': 560, 'y': 149}, {'x': 642, 'y': 145}, {'x': 643, 'y': 181}, {'x': 562, 'y': 185}]}}], 'fullTextAnnotation': {'pages': [{'width': 1286, 'height': 639, 'blocks': [{'boundingBox': {'vertices': [{'x': 542, 'y': 55}, {'x': 667, 'y': 51}, {'x': 671, 'y': 181}, {'x': 546, 'y': 185}]}, 'paragraphs': [{'boundingBox': {'vertices': [{'x': 543, 'y': 55}, {'x': 667, 'y': 53}, {'x': 668, 'y': 140}, {'x': 544, 'y': 142}]}, 'words': [{'boundingBox': {'vertices': [{'x': 543, 'y': 55}, {'x': 667, 'y': 53}, {'x': 668, 'y': 140}, {'x': 544, 'y': 142}]}, 'symbols': [{'boundingBox': {'vertices': [{'x': 543, 'y': 56}, {'x': 585, 'y': 55}, {'x': 586, 'y': 141}, {'x': 544, 'y': 142}]}, 'text': 'd', 'confidence': 0.90836555}, {'boundingBox': {'vertices': [{'x': 582, 'y': 55}, {'x': 633, 'y': 54}, {'x': 634, 'y': 140}, {'x': 583, 'y': 141}]}, 'text': 'o', 'confidence': 0.87361646}, {'property': {'detectedBreak': {'type': 'LINE_BREAK'}}, 'boundingBox': {'vertices': [{'x': 617, 'y': 54}, {'x': 667, 'y': 53}, {'x': 668, 'y': 139}, {'x': 618, 'y': 140}]}, 'text': 'g', 'confidence': 0.9316926}], 'confidence': 0.9045582}], 'confidence': 0.9045582}, {'boundingBox': {'vertices': [{'x': 560, 'y': 149}, {'x': 642, 'y': 145}, {'x': 643, 'y': 181}, {'x': 562, 'y': 185}]}, 'words': [{'boundingBox': {'vertices': [{'x': 560, 'y': 149}, {'x': 642, 'y': 145}, {'x': 643, 'y': 181}, {'x': 562, 'y': 185}]}, 'symbols': [{'boundingBox': {'vertices': [{'x': 560, 'y': 150}, {'x': 592, 'y': 149}, {'x': 593, 'y': 184}, {'x': 562, 'y': 185}]}, 'text': 'C', 'confidence': 0.44900727}, {'boundingBox': {'vertices': [{'x': 584, 'y': 148}, {'x': 616, 'y': 147}, {'x': 617, 'y': 182}, {'x': 586, 'y': 183}]}, 'text': 'a', 'confidence': 0.7346948}, {'property': {'detectedBreak': {'type': 'LINE_BREAK'}}, 'boundingBox': {'vertices': [{'x': 612, 'y': 147}, {'x': 642, 'y': 146}, {'x': 643, 'y': 181}, {'x': 614, 'y': 182}]}, 'text': 't', 'confidence': 0.6299783}], 'confidence': 0.60456014}], 'confidence': 0.60456014}], 'blockType': 'TEXT', 'confidence': 0.75455916}], 'confidence': 0.75455916}], 'text': 'dog\\nCat'}}]}\n",
      "dog\n",
      "Cat\n",
      "dog\n",
      "Cat\n",
      "Cells updated: 1\n"
     ]
    }
   ],
   "source": [
    "# Install necessary libraries if not already installed\n",
    "# Note: Uncomment the next line if you encounter issues with imports\n",
    "# !pip install google-cloud-vision google-auth google-auth-oauthlib google-api-python-client torch torchvision\n",
    "\n",
    "# imports for auth, image processing, and PyTorch model\n",
    "import requests\n",
    "import base64\n",
    "from google.cloud import vision\n",
    "from google.oauth2 import service_account\n",
    "from googleapiclient.discovery import build\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "# TODO -> put the path to your API key and service account file\n",
    "api_key_file_path = '/Users/angelokaram/Desktop/Sac State Folders/Sac State Spring 2024/CSC 190/Senior-Project/private_keys.txt'\n",
    "SERVICE_ACCOUNT_FILE = '/Users/angelokaram/Desktop/Sac State Folders/Sac State Spring 2024/CSC 190/Senior-Project/test-ai-sheet-1cbe18b0629d.json'\n",
    "\n",
    "# Read the API key from the file\n",
    "def get_api_key_from_file(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "            if len(lines) >= 2:\n",
    "                # API key on first line\n",
    "                return lines[0].strip()\n",
    "            else:\n",
    "                raise ValueError(\"API key not found in the file.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to read the API key from file: {e}\")\n",
    "        return None\n",
    "\n",
    "# Authentication and setup\n",
    "API_KEY = get_api_key_from_file(api_key_file_path)\n",
    "SCOPES = ['https://www.googleapis.com/auth/spreadsheets']\n",
    "credentials = service_account.Credentials.from_service_account_file(\n",
    "    SERVICE_ACCOUNT_FILE, scopes=SCOPES)\n",
    "service = build('sheets', 'v4', credentials=credentials)\n",
    "\n",
    "# Spreadsheet details\n",
    "SPREADSHEET_ID = '157Dpz8bSe0NMoUAcElBKG6InbRuiboWqht11-tdlnNA'\n",
    "READ_RANGE_NAME = 'Sheet1!A2'  # Read Column A, Row 2\n",
    "WRITE_RANGE_NAME = 'Sheet1!D2'  # Write to Column D, Row 2\n",
    "\n",
    "# Preprocess the image (improves accuracy)\n",
    "def preprocess_image(image_url):\n",
    "    response = requests.get(image_url)\n",
    "    img = Image.open(io.BytesIO(response.content)).convert('L')\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "    return transform(img).unsqueeze(0)\n",
    "\n",
    "# added CNN model training to handle different handwriting styles.\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(32 * 128 * 128, 10) \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = x.view(-1, 32 * 128 * 128)\n",
    "        x = torch.sigmoid(self.fc1(x))\n",
    "        return x\n",
    "\n",
    "# Image encoding for Google Vision API\n",
    "def encode_image(image_url):\n",
    "    \"\"\"Fetches an image from the URL and encodes it in base64.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(image_url)\n",
    "        response.raise_for_status()  # raise exception for HTTP errors\n",
    "        return base64.b64encode(response.content).decode()\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Failed to fetch image from URL: {e}\")\n",
    "        return None\n",
    "\n",
    "# Detect text using Google Vision API\n",
    "def detect_text_via_api(image_url):\n",
    "    url = f\"https://vision.googleapis.com/v1/images:annotate?key={API_KEY}\"\n",
    "    headers = {'Content-Type': 'application/json'}\n",
    "    image_content = encode_image(image_url)\n",
    "    \n",
    "    body = {\n",
    "        \"requests\": [\n",
    "            {\n",
    "                \"image\": {\n",
    "                    \"content\": image_content\n",
    "                },\n",
    "                \"features\": [\n",
    "                    {\"type\": \"DOCUMENT_TEXT_DETECTION\"}  # better type for handwritten text\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # API request and response handling\n",
    "    response = requests.post(url, headers=headers, json=body)\n",
    "    result = response.json()\n",
    "    print(result)  # Debugging: prints the API response\n",
    "\n",
    "    # Process the response to identify symbols and text\n",
    "    if 'responses' in result and len(result['responses']) > 0 and 'textAnnotations' in result['responses'][0]:\n",
    "        annotations = result['responses'][0]['textAnnotations']\n",
    "        for annotation in annotations:\n",
    "            description = annotation['description']\n",
    "            print(description)  # Print out each detected text block for inspection\n",
    "        return annotations[0]['description']\n",
    "    else:\n",
    "        return 'No text detected'\n",
    "\n",
    "# Call functions to read image URL from Google Sheets and update with detected text\n",
    "def read_and_update_sheet():\n",
    "    # Read the image URL from the sheet\n",
    "    result = service.spreadsheets().values().get(\n",
    "        spreadsheetId=SPREADSHEET_ID, range=READ_RANGE_NAME).execute()\n",
    "    image_url = result.get('values', [[None]])[0][0]\n",
    "    if image_url:\n",
    "        detected_text = detect_text_via_api(image_url)\n",
    "        # Write what text was detected back to the sheet\n",
    "        values = [[detected_text]]\n",
    "        body = {'values': values}\n",
    "        update_result = service.spreadsheets().values().update(\n",
    "            spreadsheetId=SPREADSHEET_ID, range=WRITE_RANGE_NAME,\n",
    "            valueInputOption='USER_ENTERED', body=body).execute()\n",
    "        print(f'Cells updated: {update_result.get(\"updatedCells\")}')\n",
    "    else:\n",
    "        print(\"No URL found in the specified cell.\")\n",
    "\n",
    "# Execute the main function\n",
    "read_and_update_sheet()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (torch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a665b5d41d17b532ea9890333293a1b812fa0b73c9c25c950b3cedf1bebd0438"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
