{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_loader\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from torchvision.transforms import v2 as transforms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines the path to the folder with data in it\n",
    "train_dir = Path(\"mbrimberry_files\\Submissions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makes transforms and loads the datasets form the directories\n",
    "trans = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToImage(),\n",
    "        transforms.ToDtype(torch.float32, scale=True),\n",
    "        transforms.Resize(size=(1056,816))\n",
    "    ])\n",
    "desk_data = data_loader.IndividualIMGDataset(targ_dir=train_dir,transform=trans)\n",
    "packet_data = data_loader.IndividualIMGDataset(targ_dir=train_dir,transform=trans,type = \"packet\")\n",
    "caddy_data = data_loader.IndividualIMGDataset(targ_dir=train_dir,transform=trans,type = \"caddy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The image is represented as a big tensor\n",
    "# The labels and boxes are in a list which is returned second\n",
    "packet_data[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying Dataset\n",
    "These are a few methods for viewing the displayed data\n",
    "\n",
    "Keep in mind that this is different then working with data_loader which stores the data in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can use matplotlib to display the image tensor\n",
    "import matplotlib.pyplot as plt\n",
    "image, targets = packet_data[2]\n",
    "print(f\"{image.shape}\")\n",
    "image_permute = image.permute(1,2,0)\n",
    "print(f\"{image_permute.shape}\")\n",
    "fig, ax = plt.subplots(1)\n",
    "ax.imshow(image_permute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will return the image and target data for the third datapoint\n",
    "img, targets = desk_data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image tensor\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coordinates for bounding boxes\n",
    "# They are in center x, center y, width, heigh format\n",
    "# The values go from 0.0 to 1.0 and go propotinal to the page (EX: 1.0 for x would mean center of the box is all the way to the right of the image)\n",
    "targets[\"boxes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These labels are based on the class.txt file. 0 referes to the first entry and 1 refers to the second entry. \n",
    "targets[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Amount of desk images\n",
    "len(desk_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amount of packet images\n",
    "len(packet_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the classes the correspond with 0 and 1 for the desk and packet data\n",
    "desk_data.classes, packet_data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This slider shows all of the images in the desk dataset with there bounding boxes\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Display an image and its prediction\n",
    "def display_prediction(index):\n",
    "    image, targets = desk_data[index]\n",
    "    bimg = data_loader.DrawBox(image,targets[\"boxes\"],targets[\"labels\"])\n",
    "    image_permute = bimg.permute(1,2,0)\n",
    "    plt.imshow(image_permute)\n",
    "    plt.show()\n",
    "\n",
    "# Slider widget (use the slider below)\n",
    "slider = widgets.IntSlider(value=0, min=0, max=len(desk_data)-1, step=1, description='Index:')\n",
    "widgets.interactive(display_prediction, index=slider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This slider shows all of the images in the packet dataset with there bounding boxes\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Display an image and its prediction\n",
    "def display_prediction(index):\n",
    "    image, targets = packet_data[index]\n",
    "    bimg = data_loader.DrawBox(image,targets[\"boxes\"],targets[\"labels\"])\n",
    "    image_permute = bimg.permute(1,2,0)\n",
    "    plt.imshow(image_permute)\n",
    "    plt.show()\n",
    "\n",
    "# Slider widget (use the slider below)\n",
    "slider = widgets.IntSlider(value=0, min=0, max=len(packet_data)-1, step=1, description='Index:')\n",
    "widgets.interactive(display_prediction, index=slider)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader\n",
    "\n",
    "This section puts the dataset into the dataloader and we look at the data in a batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE= 32\n",
    "NUM_WORKERS = 0\n",
    "\n",
    "dataloader = DataLoader(dataset=packet_data,\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        collate_fn=data_loader.collate_fn,\n",
    "                        num_workers=NUM_WORKERS,\n",
    "                        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_desk = DataLoader(dataset=desk_data,\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        collate_fn=data_loader.collate_fn,\n",
    "                        num_workers=NUM_WORKERS,\n",
    "                        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_caddy = DataLoader(dataset=caddy_data,\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        collate_fn=data_loader.collate_fn,\n",
    "                        num_workers=NUM_WORKERS,\n",
    "                        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To look at a batch you can use this\n",
    "img, targets = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A for loop that goes through all the batches\n",
    "# Might need to use this for CNN\n",
    "# This tests all data for all batches\n",
    "#\n",
    "for imgs, targ in dataloader:\n",
    "    print(imgs.shape, targ[\"boxes\"].shape, targ[\"labels\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets[\"boxes\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, targets = next(iter(dataloader))\n",
    "from torchvision.utils import draw_bounding_boxes\n",
    "bimg = data_loader.DrawBox(img[5],targets[\"boxes\"][5],targets[\"labels\"][5])\n",
    "image_permute = bimg.permute(1,2,0)\n",
    "fig, ax = plt.subplots(1)\n",
    "ax.imshow(image_permute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Display an image and its prediction\n",
    "def display_prediction(index):\n",
    "    image, targets = packet_data[index]\n",
    "    bimg = data_loader.DrawBox(image,targets[\"boxes\"],targets[\"labels\"])\n",
    "    image_permute = bimg.permute(1,2,0)\n",
    "    plt.imshow(image_permute)\n",
    "    plt.show()\n",
    "\n",
    "# Slider widget (use the slider below)\n",
    "slider = widgets.IntSlider(value=0, min=0, max=len(packet_data)-1, step=1, description='Index:')\n",
    "widgets.interactive(display_prediction, index=slider)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying Dataloader\n",
    "This makes the dataset and puts is through a dataloader.\n",
    "It takes that dataloader extracts a batch from it and uses matplotlib to display it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import data_loader\n",
    "import torch\n",
    "from torchvision.transforms import v2 as transforms\n",
    "trans = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToImage(),\n",
    "        transforms.ToDtype(torch.float32, scale=True),\n",
    "        transforms.Resize(size=(1056,816))\n",
    "    ])\n",
    "train_dir = Path(\"mbrimberry_files\\Submissions\")\n",
    "\n",
    "#Can define type to \"desk\" or \"packet\" to change dataset\n",
    "dataloader = data_loader.get_individual_data_loader(targ_dir=train_dir, transform = trans, type = \"packet\") \n",
    "\n",
    "# turns img and targ to be the batch of the next data\n",
    "data = iter(dataloader)\n",
    "img, targ = next(data)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targ[\"labels\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Display an image and its prediction\n",
    "def display_prediction(index):\n",
    "    bimg = data_loader.DrawBox(img[index],targ[\"boxes\"][index],targ[\"labels\"][index])\n",
    "    image_permute = bimg.permute(1,2,0)\n",
    "    plt.imshow(image_permute)\n",
    "    plt.show()\n",
    "\n",
    "# Slider widget (use the slider below)\n",
    "slider = widgets.IntSlider(value=0, min=0, max=len(img)-1, step=1, description='Index:')\n",
    "widgets.interactive(display_prediction, index=slider)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchCUDA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
